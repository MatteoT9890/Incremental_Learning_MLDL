{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTlj0v4qrzFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "149b7137-bbda-49fd-cf3b-1e1b41c597dd"
      },
      "source": [
        "!rm -r 'IncrementalLeraningMLDL'\n",
        "!git clone \"https://github.com/wAnto97/IncrementalLeraningMLDL\"\n",
        "from IncrementalLeraningMLDL.src.CIFAR100_dataset import MyCIFAR100\n",
        "from IncrementalLeraningMLDL.src.Utils import Utils\n",
        "from IncrementalLeraningMLDL.src.MyNet import MyNet\n",
        "from IncrementalLeraningMLDL.src.KNN import KNN\n",
        "from IncrementalLeraningMLDL.src.Exemplars import Exemplars\n",
        "from IncrementalLeraningMLDL.src.Loss import Loss\n",
        "\n",
        "import numpy as np\n",
        "import sys\n",
        "import copy\n",
        "from torch.backends import cudnn\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import  DataLoader\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IncrementalLeraningMLDL'...\n",
            "remote: Enumerating objects: 140, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/140)\u001b[K\rremote: Counting objects:   1% (2/140)\u001b[K\rremote: Counting objects:   2% (3/140)\u001b[K\rremote: Counting objects:   3% (5/140)\u001b[K\rremote: Counting objects:   4% (6/140)\u001b[K\rremote: Counting objects:   5% (7/140)\u001b[K\rremote: Counting objects:   6% (9/140)\u001b[K\rremote: Counting objects:   7% (10/140)\u001b[K\rremote: Counting objects:   8% (12/140)\u001b[K\rremote: Counting objects:   9% (13/140)\u001b[K\rremote: Counting objects:  10% (14/140)\u001b[K\rremote: Counting objects:  11% (16/140)\u001b[K\rremote: Counting objects:  12% (17/140)\u001b[K\rremote: Counting objects:  13% (19/140)\u001b[K\rremote: Counting objects:  14% (20/140)\u001b[K\rremote: Counting objects:  15% (21/140)\u001b[K\rremote: Counting objects:  16% (23/140)\u001b[K\rremote: Counting objects:  17% (24/140)\u001b[K\rremote: Counting objects:  18% (26/140)\u001b[K\rremote: Counting objects:  19% (27/140)\u001b[K\rremote: Counting objects:  20% (28/140)\u001b[K\rremote: Counting objects:  21% (30/140)\u001b[K\rremote: Counting objects:  22% (31/140)\u001b[K\rremote: Counting objects:  23% (33/140)\u001b[K\rremote: Counting objects:  24% (34/140)\u001b[K\rremote: Counting objects:  25% (35/140)\u001b[K\rremote: Counting objects:  26% (37/140)\u001b[K\rremote: Counting objects:  27% (38/140)\u001b[K\rremote: Counting objects:  28% (40/140)\u001b[K\rremote: Counting objects:  29% (41/140)\u001b[K\rremote: Counting objects:  30% (42/140)\u001b[K\rremote: Counting objects:  31% (44/140)\u001b[K\rremote: Counting objects:  32% (45/140)\u001b[K\rremote: Counting objects:  33% (47/140)\u001b[K\rremote: Counting objects:  34% (48/140)\u001b[K\rremote: Counting objects:  35% (49/140)\u001b[K\rremote: Counting objects:  36% (51/140)\u001b[K\rremote: Counting objects:  37% (52/140)\u001b[K\rremote: Counting objects:  38% (54/140)\u001b[K\rremote: Counting objects:  39% (55/140)\u001b[K\rremote: Counting objects:  40% (56/140)\u001b[K\rremote: Counting objects:  41% (58/140)\u001b[K\rremote: Counting objects:  42% (59/140)\u001b[K\rremote: Counting objects:  43% (61/140)\u001b[K\rremote: Counting objects:  44% (62/140)\u001b[K\rremote: Counting objects:  45% (63/140)\u001b[K\rremote: Counting objects:  46% (65/140)\u001b[K\rremote: Counting objects:  47% (66/140)\u001b[K\rremote: Counting objects:  48% (68/140)\u001b[K\rremote: Counting objects:  49% (69/140)\u001b[K\rremote: Counting objects:  50% (70/140)\u001b[K\rremote: Counting objects:  51% (72/140)\u001b[K\rremote: Counting objects:  52% (73/140)\u001b[K\rremote: Counting objects:  53% (75/140)\u001b[K\rremote: Counting objects:  54% (76/140)\u001b[K\rremote: Counting objects:  55% (77/140)\u001b[K\rremote: Counting objects:  56% (79/140)\u001b[K\rremote: Counting objects:  57% (80/140)\u001b[K\rremote: Counting objects:  58% (82/140)\u001b[K\rremote: Counting objects:  59% (83/140)\u001b[K\rremote: Counting objects:  60% (84/140)\u001b[K\rremote: Counting objects:  61% (86/140)\u001b[K\rremote: Counting objects:  62% (87/140)\u001b[K\rremote: Counting objects:  63% (89/140)\u001b[K\rremote: Counting objects:  64% (90/140)\u001b[K\rremote: Counting objects:  65% (91/140)\u001b[K\rremote: Counting objects:  66% (93/140)\u001b[K\rremote: Counting objects:  67% (94/140)\u001b[K\rremote: Counting objects:  68% (96/140)\u001b[K\rremote: Counting objects:  69% (97/140)\u001b[K\rremote: Counting objects:  70% (98/140)\u001b[K\rremote: Counting objects:  71% (100/140)\u001b[K\rremote: Counting objects:  72% (101/140)\u001b[K\rremote: Counting objects:  73% (103/140)\u001b[K\rremote: Counting objects:  74% (104/140)\u001b[K\rremote: Counting objects:  75% (105/140)\u001b[K\rremote: Counting objects:  76% (107/140)\u001b[K\rremote: Counting objects:  77% (108/140)\u001b[K\rremote: Counting objects:  78% (110/140)\u001b[K\rremote: Counting objects:  79% (111/140)\u001b[K\rremote: Counting objects:  80% (112/140)\u001b[K\rremote: Counting objects:  81% (114/140)\u001b[K\rremote: Counting objects:  82% (115/140)\u001b[K\rremote: Counting objects:  83% (117/140)\u001b[K\rremote: Counting objects:  84% (118/140)\u001b[K\rremote: Counting objects:  85% (119/140)\u001b[K\rremote: Counting objects:  86% (121/140)\u001b[K\rremote: Counting objects:  87% (122/140)\u001b[K\rremote: Counting objects:  88% (124/140)\u001b[K\rremote: Counting objects:  89% (125/140)\u001b[K\rremote: Counting objects:  90% (126/140)\u001b[K\rremote: Counting objects:  91% (128/140)\u001b[K\rremote: Counting objects:  92% (129/140)\u001b[K\rremote: Counting objects:  93% (131/140)\u001b[K\rremote: Counting objects:  94% (132/140)\u001b[K\rremote: Counting objects:  95% (133/140)\u001b[K\rremote: Counting objects:  96% (135/140)\u001b[K\rremote: Counting objects:  97% (136/140)\u001b[K\rremote: Counting objects:  98% (138/140)\u001b[K\rremote: Counting objects:  99% (139/140)\u001b[K\rremote: Counting objects: 100% (140/140)\u001b[K\rremote: Counting objects: 100% (140/140), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 1324 (delta 93), reused 98 (delta 53), pack-reused 1184\u001b[K\n",
            "Receiving objects: 100% (1324/1324), 10.86 MiB | 21.46 MiB/s, done.\n",
            "Resolving deltas: 100% (894/894), done.\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jbSB5id_PC9",
        "colab_type": "text"
      },
      "source": [
        "**Loading data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NtjfRgDVse6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e5780611-525b-4123-ff8e-3521eeecb2d6"
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "                                      transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                       transforms.Normalize( (0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))]) # Normalizes tensor with mean and standard deviation\n",
        "                                      #transforms.Normalize( (0.5, 0.5, 0.5),(0.5, 0.5, 0.5))]) # Normalizes tensor with mean and standard deviation\n",
        "\n",
        "\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize( (0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))])  \n",
        "training_set = MyCIFAR100('/content',train=True, n_groups=10, transform=train_transform, download=True,random_state = 653)\n",
        "test_set = MyCIFAR100('/content',train=False, n_groups=10, transform=eval_transform, download=True,random_state = 653)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAub61CI_RQa",
        "colab_type": "text"
      },
      "source": [
        "**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-do-BtKUI4F-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'  \n",
        "\n",
        "BATCH_SIZE = 128      # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch strain_dataloaderize, learning rate should change by the same factor to have comparable results\n",
        "LR = 2              # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 1e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 70             # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = [49,63]      # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.2                 # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10\n",
        "\n",
        "CLASSES_PER_GROUP=10\n",
        "NUM_GROUPS=10\n",
        "NUM_EXEMPLARS=2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuVdgbGr-Y_C",
        "colab_type": "text"
      },
      "source": [
        "**Utils functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7hyAp8bJI8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(val_dataloader,knn,conf_matrix=False):\n",
        "    running_corrects = 0\n",
        "    y_pred = []\n",
        "    all_labels = []\n",
        "    for images, labels,_ in val_dataloader:\n",
        "\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        # Get predictions\n",
        "        preds = knn.classify(images)\n",
        "        # Update Corrects\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        y_pred += list(map(lambda x : x.item(),preds))\n",
        "        all_labels += list(labels)\n",
        "\n",
        "        # Calculate Accuracy\n",
        "    accuracy = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    if(conf_matrix == True):\n",
        "        all_labels = list(map(lambda label : label.item(),all_labels))\n",
        "        return accuracy,confusion_matrix(y_pred,np.array(all_labels))\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDvEQernpNj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_loaders(train_dataloader):\n",
        "    all_labels = []\n",
        "    for images,labels,_ in train_dataloader:\n",
        "      all_labels += list(map(lambda x: x.item(),labels))\n",
        "\n",
        "    print(np.unique(all_labels,return_counts=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kitbSfdqhd9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def after_training(step,n_old_classes,exemplar_dataloader,train_dataloader_exemplars,exemplars,knn,net,utils,training_set,type_reduction = 'random'):\n",
        "  \n",
        "  images_indices = utils.create_images_indices(exemplar_dataloader,step)\n",
        "  knn.update(net,train_dataloader_exemplars)  \n",
        "  \n",
        "  if len(exemplars.exemplar_set) > 0:\n",
        "    print(\"Reducing the exemplar set..\")\n",
        "    exemplars.reduce_exemplars(n_old_classes)\n",
        "  \n",
        "  print(\"Building the exemplar set...\")\n",
        "  if type_reduction == 'random':\n",
        "    exemplars.build_exemplars_random(images_indices,n_old_classes)\n",
        "  elif type_reduction == 'herding':\n",
        "    exemplars.build_exemplars_herding(net,images_indices,n_old_classes)\n",
        "\n",
        "  return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtaJ1cyq-dQJ",
        "colab_type": "text"
      },
      "source": [
        "**Main**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbJtQL1hJagQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b90d216-842c-40d2-cfc7-c9af59e509c4"
      },
      "source": [
        "myNet = MyNet(n_classes=CLASSES_PER_GROUP)\n",
        "knn = KNN()\n",
        "exemplars = Exemplars()\n",
        "utils = Utils()\n",
        "myLoss = Loss()\n",
        "typeScheduler='multistep' # In this case it can be only set to multistep\n",
        "\n",
        "#Creating dataloader for the first group of 10 classes\n",
        "train_dataloader_exemplars,test_dataloader = utils.create_dataloaders_icarl(training_set,test_set,1,exemplars.exemplar_set,BATCH_SIZE)\n",
        "\n",
        "old_outputs=[]\n",
        "\n",
        "for i in range(NUM_GROUPS):\n",
        "    step=i+1 \n",
        "    print(\"STARTING KNN TRAINING WITH GROUP:\\t\",step)  \n",
        "\n",
        "    n_old_classes = CLASSES_PER_GROUP*(step-1)\n",
        "    if step > 1:\n",
        "      myNet.update_network(myNet.net,CLASSES_PER_GROUP + n_old_classes,myNet.init_weights)\n",
        "      train_dataloader_exemplars,test_dataloader = utils.create_dataloaders_icarl(training_set,test_set,step,exemplars.exemplar_set,BATCH_SIZE)\n",
        "      test_loaders(train_dataloader_exemplars)\n",
        "    \n",
        "    optimizer,scheduler = myNet.prepare_training(LR,MOMENTUM,WEIGHT_DECAY,STEP_SIZE,GAMMA,typeScheduler=typeScheduler)\n",
        "\n",
        "    classification_losses = []\n",
        "    distillation_losses = []\n",
        "\n",
        "    myNet.net.to(DEVICE)\n",
        "    cudnn.benchmark \n",
        "\n",
        "    for epoch in range(1):\n",
        "        running_correct_train = 0\n",
        "        if typeScheduler == 'multistep':\n",
        "          print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_last_lr()))\n",
        "\n",
        "        myNet.net.train() # Set Network to train mode\n",
        "        current_step = 0\n",
        "        for images, labels, _ in train_dataloader_exemplars:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            \n",
        "            #Set all gradients to zero\n",
        "            optimizer.zero_grad() \n",
        "\n",
        "            #Computing output and creating the acyclic graph for updating the gradients\n",
        "            outputs = myNet.net(images) \n",
        "\n",
        "            #Computing predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            \n",
        "            #Get predictions of the previous net\n",
        "            if(step > 1):\n",
        "                old_outputs = myNet.get_old_outputs(images,labels)\n",
        "\n",
        "\n",
        "            #Computing loss\n",
        "            loss,clf_loss,dist_loss = myLoss.icarl_loss(old_outputs,outputs,labels,step,current_step,utils,CLASSES_PER_GROUP)\n",
        "            classification_losses.append(clf_loss.item())\n",
        "            distillation_losses.append(dist_loss.item())\n",
        "\n",
        "            #Calculate correct predictions\n",
        "            running_correct_train += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            #Accumulate gradients\n",
        "            loss.backward()  \n",
        "\n",
        "            # Update weights based on accumulated gradients  \n",
        "            optimizer.step()\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        #Calculate training accuracy\n",
        "        train_accuracy = running_correct_train/len(train_dataloader_exemplars.dataset)\n",
        "        print(\"Accuracy on the training :\\t\",train_accuracy)\n",
        "\n",
        "        if typeScheduler == 'multistep':\n",
        "            scheduler.step()\n",
        "\n",
        "    #Handling Exemplars\n",
        "    exemplar_dataloader = DataLoader(training_set.get_group(step),batch_size=BATCH_SIZE,drop_last=False,num_workers=4)\n",
        "    after_training(step,n_old_classes,exemplar_dataloader,train_dataloader_exemplars,exemplars,knn,myNet.net,utils,training_set,type_reduction='random')\n",
        "\n",
        "    #Test\n",
        "    test_accuracy,test_matrix = validation(test_dataloader,knn,conf_matrix=True)\n",
        "    print(\"Accuracy on the test :\\t\",test_accuracy)\n",
        "\n",
        "    #Writing on file    \n",
        "    utils.writeOnFileMetrics('KNNMetrics.json', step, [train_accuracy,None,test_accuracy,test_matrix.tolist()])\n",
        "    utils.writeOnFileLosses('KNNLosses.json', step, [classification_losses,distillation_losses])\n",
        "    !cp  './KNNMetrics.json' './gdrive/My Drive/KNNMetrics.json'\n",
        "    !cp  'KNNLosses.json' './gdrive/My Drive/KNNLosses.json'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STARTING KNN TRAINING WITH GROUP:\t 1\n",
            "Starting epoch 1/70, LR = [0.2]\n",
            "Accuracy on the training :\t 0.1428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
            "                     weights='uniform')\n",
            "Building the exemplar set...\n",
            "Build: 200\n",
            "Accuracy on the test :\t 0.351\n",
            "STARTING KNN TRAINING WITH GROUP:\t 2\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19]), array([196, 199, 198, 199, 200, 194, 198, 198, 194, 197, 494, 496, 494,\n",
            "       492, 497, 496, 496, 494, 494, 486]))\n",
            "Starting epoch 1/70, LR = [0.2]\n",
            "Accuracy on the training :\t 0.04528571428571428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
            "                     weights='uniform')\n",
            "Reducing the exemplar set..\n",
            "Reduced: 100\n",
            "Building the exemplar set...\n",
            "Build: 100\n",
            "Accuracy on the test :\t 0.2185\n",
            "STARTING KNN TRAINING WITH GROUP:\t 3\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]), array([ 98,  99,  99,  99, 100, 100, 100,  98,  99,  97,  99,  98,  98,\n",
            "       100, 100,  98,  99, 100,  97,  99, 495, 497, 494, 495, 493, 492,\n",
            "       492, 490, 497, 490]))\n",
            "Starting epoch 1/70, LR = [0.2]\n",
            "Accuracy on the training :\t 0.03242857142857143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
            "                     weights='uniform')\n",
            "Reducing the exemplar set..\n",
            "Reduced: 66\n",
            "Building the exemplar set...\n",
            "Build: 66\n",
            "Accuracy on the test :\t 0.13166666666666665\n",
            "STARTING KNN TRAINING WITH GROUP:\t 4\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39]), array([ 66,  66,  65,  66,  65,  66,  65,  66,  65,  64,  64,  65,  65,\n",
            "        65,  66,  66,  65,  66,  65,  65,  64,  66,  65,  66,  65,  65,\n",
            "        65,  65,  64,  65, 493, 493, 494, 499, 494, 497, 497, 497, 496,\n",
            "       496]))\n",
            "Starting epoch 1/70, LR = [0.2]\n",
            "Accuracy on the training :\t 0.025501432664756445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
            "                     weights='uniform')\n",
            "Reducing the exemplar set..\n",
            "Reduced: 50\n",
            "Building the exemplar set...\n",
            "Build: 50\n",
            "Accuracy on the test :\t 0.10775\n",
            "STARTING KNN TRAINING WITH GROUP:\t 5\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]), array([ 49,  49,  49,  50,  50,  48,  50,  50,  49,  48,  50,  50,  50,\n",
            "        50,  47,  50,  50,  49,  49,  50,  50,  50,  50,  49,  49,  48,\n",
            "        50,  50,  49,  50,  50,  49,  50,  50,  49,  48,  50,  50,  50,\n",
            "        50, 494, 494, 491, 490, 497, 496, 491, 490, 494, 497]))\n",
            "Starting epoch 1/70, LR = [0.2]\n",
            "Accuracy on the training :\t 0.02242857142857143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
            "                     weights='uniform')\n",
            "Reducing the exemplar set..\n",
            "Reduced: 40\n",
            "Building the exemplar set...\n",
            "Build: 40\n",
            "Accuracy on the test :\t 0.0714\n",
            "STARTING KNN TRAINING WITH GROUP:\t 6\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59]), array([ 40,  40,  37,  39,  40,  38,  37,  39,  39,  40,  40,  39,  40,\n",
            "        39,  40,  39,  38,  40,  39,  40,  40,  39,  40,  40,  39,  40,\n",
            "        40,  39,  40,  40,  39,  40,  40,  40,  39,  40,  40,  39,  40,\n",
            "        39,  39,  39,  40,  39,  39,  40,  39,  39,  40,  40, 492, 497,\n",
            "       496, 491, 495, 493, 496, 494, 494, 494]))\n",
            "Starting epoch 1/70, LR = [0.2]\n",
            "Accuracy on the training :\t 0.019142857142857142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
            "                     weights='uniform')\n",
            "Reducing the exemplar set..\n",
            "Reduced: 33\n",
            "Building the exemplar set...\n",
            "Build: 33\n",
            "Accuracy on the test :\t 0.06633333333333333\n",
            "STARTING KNN TRAINING WITH GROUP:\t 7\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69]), array([ 33,  32,  32,  32,  33,  33,  30,  33,  33,  33,  33,  33,  33,\n",
            "        32,  33,  33,  32,  33,  33,  33,  33,  32,  33,  33,  32,  33,\n",
            "        33,  33,  32,  33,  33,  33,  32,  32,  33,  33,  33,  33,  33,\n",
            "        32,  32,  33,  33,  33,  33,  33,  32,  32,  33,  33,  32,  32,\n",
            "        33,  33,  33,  32,  33,  33,  33,  33, 492, 491, 498, 499, 495,\n",
            "       496, 494, 496, 496, 495]))\n",
            "Starting epoch 1/70, LR = [0.2]\n",
            "Accuracy on the training :\t 0.01489971346704871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
            "                     weights='uniform')\n",
            "Reducing the exemplar set..\n",
            "Reduced: 28\n",
            "Building the exemplar set...\n",
            "Build: 28\n",
            "Accuracy on the test :\t 0.05728571428571429\n",
            "STARTING KNN TRAINING WITH GROUP:\t 8\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]), array([ 28,  28,  27,  27,  28,  28,  27,  28,  28,  28,  28,  27,  28,\n",
            "        28,  28,  28,  28,  28,  27,  28,  28,  28,  28,  28,  28,  28,\n",
            "        28,  28,  28,  28,  28,  27,  27,  28,  28,  28,  27,  27,  28,\n",
            "        28,  28,  28,  28,  28,  28,  28,  27,  28,  28,  28,  28,  28,\n",
            "        28,  28,  27,  28,  28,  27,  28,  27,  28,  28,  28,  27,  28,\n",
            "        28,  28,  26,  28,  28, 496, 496, 499, 497, 498, 496, 495, 495,\n",
            "       499, 497]))\n",
            "Starting epoch 1/70, LR = [0.2]\n",
            "Accuracy on the training :\t 0.02514367816091954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')\n",
            "Reducing the exemplar set..\n",
            "Reduced: 25\n",
            "Building the exemplar set...\n",
            "Build: 25\n",
            "Accuracy on the test :\t 0.0415\n",
            "STARTING KNN TRAINING WITH GROUP:\t 9\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
            "       85, 86, 87, 88, 89]), array([ 25,  25,  25,  25,  24,  25,  24,  25,  24,  25,  25,  24,  25,\n",
            "        24,  24,  23,  25,  25,  25,  23,  25,  25,  25,  25,  25,  25,\n",
            "        25,  24,  24,  25,  25,  25,  24,  24,  25,  22,  25,  25,  25,\n",
            "        24,  24,  25,  25,  24,  24,  25,  25,  25,  25,  25,  25,  25,\n",
            "        25,  25,  24,  25,  25,  24,  25,  25,  25,  25,  24,  25,  25,\n",
            "        23,  24,  25,  25,  25,  24,  25,  25,  25,  25,  24,  24,  25,\n",
            "        25,  25, 493, 494, 493, 495, 495, 493, 495, 493, 495, 496]))\n",
            "Starting epoch 1/70, LR = [0.2]\n",
            "Accuracy on the training :\t 0.021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
            "                     weights='uniform')\n",
            "Reducing the exemplar set..\n",
            "Reduced: 22\n",
            "Building the exemplar set...\n",
            "Build: 22\n",
            "Accuracy on the test :\t 0.043555555555555556\n",
            "STARTING KNN TRAINING WITH GROUP:\t 10\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
            "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
            "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
            "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([ 21,  22,  22,  22,  21,  21,  22,  22,  22,  22,  22,  22,  21,\n",
            "        22,  21,  22,  22,  22,  22,  22,  22,  22,  22,  22,  22,  22,\n",
            "        22,  22,  22,  22,  22,  22,  22,  22,  22,  22,  22,  20,  22,\n",
            "        22,  22,  22,  22,  22,  22,  21,  22,  22,  22,  22,  22,  22,\n",
            "        22,  22,  22,  22,  22,  22,  22,  22,  21,  22,  21,  22,  22,\n",
            "        22,  21,  22,  22,  22,  22,  22,  22,  22,  21,  22,  22,  22,\n",
            "        21,  21,  22,  22,  22,  22,  22,  22,  22,  22,  22,  21, 496,\n",
            "       496, 496, 496, 495, 493, 494, 496, 489, 496]))\n",
            "Starting epoch 1/70, LR = [0.2]\n",
            "Accuracy on the training :\t 0.017048710601719197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
            "                     weights='uniform')\n",
            "Reducing the exemplar set..\n",
            "Reduced: 20\n",
            "Building the exemplar set...\n",
            "Build: 20\n",
            "Accuracy on the test :\t 0.0395\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}